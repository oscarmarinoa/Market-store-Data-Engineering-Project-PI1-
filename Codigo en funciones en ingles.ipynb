{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a function that reads the relative path of a file and create a Dataframe from it. The function implements the pandas library, a for loop, conditionals\n",
    "# and try and except senteces.\n",
    "\n",
    "def reading(file):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    extension = ''\n",
    "    for i in file[::-1]:\n",
    "        extension += i\n",
    "        if i == '.':\n",
    "            break\n",
    "    extension = extension[::-1]    \n",
    "\n",
    "    if extension == '.csv' or extension == '.txt':\n",
    "        try:\n",
    "            df = pd.read_csv(file,encoding='utf-16')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                df = pd.read_csv(file,sep='|')\n",
    "\n",
    "                if len(df.columns) < 3:\n",
    "                    df = pd.read_csv(file,sep=';')\n",
    "                    \n",
    "            except:\n",
    "                df = pd.read_csv(file,encoding='utf-8', sep=';')\n",
    "        \n",
    "    elif extension == '.json':\n",
    "        df = pd.read_json(file)\n",
    "        \n",
    "    elif extension == '.parquet':\n",
    "        df = pd.read_parquet(file)\n",
    "\n",
    "    # Reordering the columns in the order.\n",
    "    df = df[['precio', 'producto_id', 'sucursal_id']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transform the Dataframe ingested, change null values and remove duplicates.data\n",
    "\n",
    "def transf_cleansing(df):\n",
    "\n",
    "    # producto_id column:\n",
    "\n",
    "    # We replace the null values for a chain of 0 characters with the same lenght that the producto_id values have (13).\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x: str(x).replace('nan','0000000000000'))\n",
    "\n",
    "    # In case that the values have point, comas and/or spaces this line of code will removed them looking for normalization of the data.\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x: x.replace(',','.').strip())\n",
    "\n",
    "    # If the values have less than 13 digits we add the number of remaining  digits to be able to execute the next slicing.\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x:  (((13 - len(x)) * '0') + x) if len(x)<13 else x)\n",
    "\n",
    "    # Using slicing we obtain the section of the data that we are interested in.\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x: str(x)[-1:-14:-1])\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x: str(x)[::-1])\n",
    "\n",
    "    # Data conversion to integers.\n",
    "    df['producto_id'] = df['producto_id'].astype('float')\n",
    "\n",
    "    # As the source data comes with values in cientific notation, we use a lambda function combined with pd.apply and format to chage the data to the desire outcome.\n",
    "    df['producto_id'] = df['producto_id'].apply(lambda x: '%13.0f'% x)\n",
    "\n",
    "  # Data conversion to integers.\n",
    "    df['producto_id'] = df['producto_id'].astype('int64')\n",
    "\n",
    "\n",
    "    # sucursal_id column:\n",
    "\n",
    "    # After loading the dataframes, some values are structured like dates (eg. 10/06/153). Therefore, it is necessary changing the values to strings and replace the / for -. \n",
    "    df['sucursal_id'] = df['sucursal_id'].apply(lambda x: str(x))\n",
    "    df['sucursal_id'] = df['sucursal_id'].str.replace('/','-').replace('/','-')\n",
    "\n",
    "\n",
    "    # precio column:\n",
    "\n",
    "    # Code section focused on managingg values with typos and nulls found in the initial csv, to convert price values into float.\n",
    "\n",
    "    # We convert the data into alphanumeric characters.\n",
    "    df['precio'] = df['precio'].apply(lambda x: str(x))\n",
    "    \n",
    "    # Price values that are longer than 10 characters are designated with the error tag. The 10 is an arbitraty lenght choose according to the prices of eatable products \n",
    "    # in a supermarket in Argentina. According to research, food products do not exceed 10 characters of value, namely, 9,999,999 Argentine pesos. \n",
    "    df['precio'] = df['precio'].apply(lambda x: 'error' if len(x) > 10 else x)\n",
    "    \n",
    "    \n",
    "    # Numbers above 10 characters are deleted since they are very large numbers and in some cases have non numeric formats, therefore,  \n",
    "    # they are not in the regular price ranges of the supermarkets. It looks like some errors were made when entering the data in the original csv. \n",
    "    toerase = df[df['precio'] == 'error'].index\n",
    "    df.drop(toerase, inplace=True)\n",
    "    \n",
    "    \n",
    "    # To convert the price column into decimal values what we do is bringing the values into numeric format with the pd.to_numeric function. Thanks to the errors = 'coerce' parameter\n",
    "    # the values with errors are converted to NaN. Later on we use a lambda functipn to replace them for 0.\n",
    "    numeric_values = pd.to_numeric(df.precio, errors='coerce')\n",
    "    df.precio = numeric_values.apply(lambda x: float(str(x).replace('nan', '0')))\n",
    "    df.precio  = df.precio.astype('float64')\n",
    "    \n",
    "    # In case that some columns remained with null values, we change them for 0. It would be a good practice to separate null values from errors, nevertheless,\n",
    "    # the source files (.csv, json, .tct etc.) come with so many of them that it is complex to handle them.\n",
    "    df = df.apply(lambda x: x.fillna(0))\n",
    "\n",
    "\n",
    "    # To finish the transformation process we return to the producto_id in order to separate the column.\n",
    "    \n",
    "    # The code consist of splitting the column producto_id into 'comercioid', 'banderaid' and 'sucursalid', and converting them into separate columns as integer values.\n",
    "    # The procedure is repeteated for each of the desired columns.\n",
    "    # The objective if indentified which products do not have values assigned correctly.\n",
    "   \n",
    "    # We split sucursal_id into comercioid, banderaid and sucursalid.\n",
    "    data = df.sucursal_id.str.split('-', expand=True)\n",
    "\n",
    "    # We gave the new columns the desire name.\n",
    "    data.columns = ['comercioid', 'banderaid', 'sucursalid']\n",
    "    \n",
    "    # This section of code carry out the transformation of alphanumeric characters into numeric values. It assing NaN to the data with errors, that is later replaced by 0.\n",
    "    num_bandera = pd.to_numeric(data.banderaid, errors = 'coerce')\n",
    "    data.banderaid = num_bandera.apply(lambda x: float(str(x).replace('nan', '0')))\n",
    "    data.banderaid = data.banderaid.astype('int64')\n",
    "\n",
    "    num_sucursal = pd.to_numeric(data.sucursalid, errors = 'coerce')\n",
    "    data.sucursalid = num_sucursal.apply(lambda x: float(str(x).replace('nan', '0')))\n",
    "    data.sucursalid = data.sucursalid.astype('int64')\n",
    "\n",
    "    num_comercio = pd.to_numeric(data.comercioid, errors = 'coerce')\n",
    "    data.comercioid = num_comercio.apply(lambda x: float(str(x).replace('nan', '0')))\n",
    "    data.comercioid = data.comercioid.astype('int64')\n",
    "\n",
    "    # Finally, we concatena the main table with the separate columns in just one dataframe.\n",
    "    df = pd.concat([df,data], axis=1)\n",
    "    \n",
    "    # This function calls a third function that is the one in charge of creating the conection with MySQL through SQLAlchemy\n",
    "    conection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conection(df):\n",
    "    from sqlalchemy import create_engine\n",
    "    mysqlengine = create_engine('mysql+pymysql://root:14Arsenal14*@127.0.0.1:3306/PI_1')\n",
    "    df.to_sql(name='precio_semana',con=mysqlengine, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ac5f2a079eb37b29a6a78efb89b55e3f5ce774c913a43ce907979c16c14b5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
